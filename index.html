<!DOCTYPE html>
<html lang="en-us">
    
<head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.49" />

    

<title>Midnight Programmer</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Midnight Programmer"/>
<meta name="twitter:description" content="Programming For Fun"/>

<meta property="og:title" content="Midnight Programmer" />
<meta property="og:description" content="Programming For Fun" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://prashantkhandelwal.github.io/" />
<meta property="og:updated_time" content="2025-11-07T05:02:00&#43;00:00"/><meta property="og:site_name" content="Midnight Programmer" />


    


<link rel="stylesheet" href="/css/hyde-hyde.css">
<link rel="stylesheet" href="/css/print.css" media="print">


    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    

<link href="https://prashantkhandelwal.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Midnight Programmer" />
<link href="https://prashantkhandelwal.github.io/index.xml" rel="feed" type="application/rss+xml" title="Midnight Programmer" />


</head>


    <body class=" ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="https://prashantkhandelwal.github.io/">Midnight Programmer</a>
      </span>
      
      
      
      <div class="author-image">
        <img src="https://prashantkhandelwal.github.io//img/prashantk.jpg" alt="Author Image" class="img--circle img--headshot element--center"> 
      </div>
      
      <p class="site__description">
         Programming For Fun 
      </p>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">Midnight Programmer</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="/archive/"><i class='fa fa-road'></i>
						<span>Archive</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/top-posts/"><i class='fa fa-star fa-fw'></i>
						<span>Top Posts</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/contact/"><i class='fa fa-envelope fa-fw'></i>
						<span>Contact</span>
					</a>
				</li>
			 
		
		</li>
	</ul>
</div>

        <section class="social">
	
	
	
	<a href="https://github.com/prashantkhandelwal" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	<a href="http://feeds.feedburner.com/MidnightProgrammer" rel="me"><i class="fa fa-rss fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	<a href="https://instagram.com/prashantkhandelwal" rel="me"><i class="fab fa-instagram fa-lg" aria-hidden="true"></i></a>
	
	
	<a href="https://linkedin.com/in/khandelwalprashant" rel="me"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	
	<a href="https://medium.com/@prashantkhandelwal" rel="me"><i class="fab fa-medium fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
</section>

      </div>
    </div>
    <p class="copyright">
      &copy; 2025 Pashant Khandelwal
      <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/2.5/in/"><img style="border-width: 0;" src="https://i.creativecommons.org/l/by-nc-sa/2.5/in/88x31.png" alt="Creative Commons License" class="thinglinkFiltered"></a>
      
    </p>
  </div>
  <div>
  </div>
</div>

        <div class="content container">
            
<div class="post-list">
  
  
  <div class="post-list__item">
    <span class="item__title--big">
      <a href="/post/chatting-with-ollama-building-a-local-llm-web-app-in-minutes/">Chatting with Ollama: Building a Local LLM Web App in Minutes</a>
      
    </span>
    <span class="item__date">
      <i class="fas fa-calendar-alt"></i> Nov 7, 2025
    </span>
    
    <span>
      
      
      
      
      
      
      <a class="badge badge-category" href="/category/ai">AI</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/ollama">OLLAMA</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/svelte">SVELTE</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/web">WEB</a>
      
      
      
      
    </span>
    <p><a href="https://ollama.com/">Ollama</a> is a lightweight and user-friendly way to run LLMs locally. No need for complex setups and it makes it super easy to explore AI chat models from the comfort of your own device.</p>

<p>This tutorial is a small part of a broader project I&rsquo;m working on, which involves using local LLMs and vision models to analyze data directly on-device. This approach helps reduce costs and addresses some of the privacy concerns raised by our customers.</p>

<p><strong>Installation and Setup</strong></p>

<p>Download and install Ollama from <a href="https://ollama.com/download">here</a>.</p>

<p>Once the setup is complete, simply launch the Ollama application—it will open a ChatGPT-like interface that lets you interact with local LLMs.</p>

<p><img src="/images/ollama-app.png" alt="Ollama App UI" /></p>

<p>This UI makes it very easy for searching, downloading and communicating with different LLMs. You can also chat with the models which are in the cloud without downloading them. Note that you require a Ollama account in order to communicate with a cloud model.</p>

<p>But we need to build a web based chat appliaction and that means that we have to interact with Ollama API which is running at <code>https://localhost:11434</code></p>

<p><img src="/images/ollama-api-running.png" alt="Ollama API" /></p>

<p>Everyting seems to be set up properly. Let&rsquo;s create a Python FastAPI endpoint which allows us to communicate with Ollama API. You can also use NodeJS, Go or .NET WebAPI to create a service endpoint.</p>

<p>Create a Python virtual environment and install the below dependencies.</p>

<pre class="brush:shell">
pip install fastapi uvicorn requests httpx
</pre>

<p>The API uses a POST request and accepts three parameters: <code>prompt</code>, <code>model</code>, and <code>stream</code>.</p>

<ul>
<li><code>prompt</code> – The input message or query from the user.</li>
<li><code>model</code> – Specifies which model to run the prompt against. If not provided, it defaults to l<code>lama3.2:latest</code>.</li>
<li><code>stream</code> – Optional setting that defaults to <code>false</code>. Set it to <code>true</code> if you want the response to appear in a typing animation, similar to ChatGPT. Note: enabling streaming requires additional changes to the code below.</li>
</ul>

<blockquote>
<p>For below version of code, requests and httpx packages are not required.</p>
</blockquote>

<pre class="brush:python">
from fastapi import FastAPI
from pydantic import BaseModel
import requests

app = FastAPI()

class PromptRequest(BaseModel):
    prompt: str
    model: str = "llama3.2:latest"  # Default model, can be overridden in the request

@app.post("/generate")
async def generate_text(request: PromptRequest):
    ollama_api_url = "http://localhost:11434/api/generate"
    
    payload = {
        "model": request.model,
        "prompt": request.prompt,
        "stream": False # True for streaming responses
    }
    
    try:
        response = requests.post(ollama_api_url, json=payload)
        response.raise_for_status()  # Raise an exception for bad status codes
        
        # Extract the generated text from Ollama's response
        generated_text = response.json()["response"]
        return {"response": generated_text}
        
    except requests.exceptions.RequestException as e:
        return {"error": f"Error communicating with Ollama: {e}"}
</pre>

<p>Run this API using <code>uvicorn</code>.</p>

<pre class="brush:shell">
uvicorn main:app
</pre>

<p>The API server will start on default <code>8000</code> port. If you wish to change the port then start the API using the below command.</p>

<pre class="brush:shell">
uvicorn main:app --port 8080
</pre>

<p>Let&rsquo;s check the API reponse using Postman.</p>

<p><img src="/images/ollama-fastapi-postman.png" alt="Postman API Call" /></p>

<p>It’s quite helpful to see the response streamed in real time, just like how ChatGPT displays it. So let&rsquo;s change the <code>stream</code> parameter to <code>true</code> and update our API code.</p>

<pre class="brush:python highlight: [21]">
from fastapi import FastAPI
from fastapi.responses import StreamingResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import httpx
import json
import os

app = FastAPI()

class PromptRequest(BaseModel):
    prompt: str
    model: str = "llama3.2:latest"

@app.post("/generate")
async def generate_text(request: PromptRequest):
    ollama_api_url = "http://localhost:11434/api/generate"
    payload = {
        "model": request.model,
        "prompt": request.prompt,
        "stream": True
    }

    async def stream_text():
        async with httpx.AsyncClient(timeout=None) as client:
            async with client.stream("POST", ollama_api_url, json=payload) as response:
                async for line in response.aiter_lines():
                    if line.strip():
                        try:
                            data = json.loads(line)
                            chunk = data.get("response", "")
                            if chunk:
                                yield chunk
                        except json.JSONDecodeError:
                            continue

    return StreamingResponse(stream_text(), media_type="text/plain")

</pre>

<p>Now we have a streaming response, let&rsquo;s make a UI, I am using Svelte. Start by creating a new project.</p>

<pre class="brush:shell">
npm create vite@latest ollama-chat -- --template svelte-ts
</pre>

<p>Update the <code>vite.config.ts</code> file to include a custom proxy setting for the development server. This setup ensures that any requests made to <code>/generate</code> are forwarded to <code>http://localhost:8000</code>, allowing the frontend to communicate seamlessly with a backend API like FastAPI. It also helps prevent CORS-related issues during development.</p>

<pre class="brush:js">
export default defineConfig({
  plugins: [svelte()],
   server: {
    proxy: {
      '/generate': 'http://localhost:8000'
    }
  }
})
</pre>

<p>The response is formatted in <code>Markdown</code>, so to render it correctly, you&rsquo;ll need an additional npm package called <code>marked</code>. You can install it using the command below.</p>

<pre class="brush:shell">
npm install marked
</pre>

<blockquote>
<p>Remember to change the port if your have setup the custom port for your API via uvicorn.</p>
</blockquote>

<p>Replace the code in <code>App.svelte</code> with the below code.</p>

<pre class="brush:jscript">
<script lang="ts">
  import { marked } from 'marked';

  let prompt: string = '';
  let chat: string = '';
  let chatHtml: string = '';
  let loading: boolean = false;

  async function sendPrompt(): Promise<void> {
    if (!prompt.trim()) return;
    chat = '';
    chatHtml = '';
    loading = true;

    const res = await fetch('/generate', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ prompt, model: 'llama3.2:latest' })
    });

    const reader = res.body?.getReader();
    const decoder = new TextDecoder('utf-8');

    if (reader) {
      while (true) {
        const { value, done } = await reader.read();
        if (done) break;
        const chunk = decoder.decode(value, { stream: true });
        chat += chunk;
        chatHtml = marked(chat); // Convert Markdown to HTML
      }
    }

    loading = false;
  }
</script>

<style>
  textarea {
    width: 100%;
    height: 100px;
    margin-bottom: 10px;
  }
  button {
    padding: 10px 20px;
  }
  #chat {
    margin-top: 20px;
    background: #243434;
    padding: 10px;
    border-radius: 5px;
    white-space: pre-wrap;
  }
  .chat-output {
    text-align: left;
  }
</style>

<h2>Ollama Chat</h2>
<label for="prompt">Enter your prompt:</label><br>
<textarea bind:value={prompt} id="prompt"></textarea><br>
<button on:click={sendPrompt} disabled={loading}>
  {loading ? 'Sending...' : 'Send'}
</button>

<div id="chat">
  {#if loading}
    <p>Loading...</p>
  {:else if chatHtml}
    <div class="chat-output">
      {@html chatHtml}
    </div>
  {:else}
    <p>No response yet.</p>
  {/if}
</div>
</style>

<h2>Ollama Chat</h2>
<label for="prompt">Enter your prompt:</label><br>
<textarea bind:value={prompt} id="prompt"></textarea><br>
<button on:click={sendPrompt} disabled={loading}>
  {loading ? 'Sending...' : 'Send'}
</button>

<div id="chat">{chat}</div>
</pre>

<p>Start the UI using the command</p>

<pre class="brush:shell">
npm run dev
</pre>

<p>We are now all set to run our local LLM based chat agent. Let&rsquo;s start by asking a question.</p>

<p><img src="/images/ollama-chat-output.png" alt="Ollama web chat interface" /></p>

<p>This code serves as a starting point. You can extend it by adding image or file upload functionality, allowing users to summarize content or ask questions based on the data within the uploaded document or image.</p>

<p>Here is the <a href="https://github.com/prashantkhandelwal/ollama-chat">Github repo</a> where you can find the entire code.</p>

  </div>
  
  <div class="post-list__item">
    <span class="item__title--big">
      <a href="/post/simple-and-cheap-create-a-diy-mouse-jiggler-with-raspberry-pi-pico/">Simple and Cheap: Create a DIY Mouse Jiggler with Raspberry Pi Pico</a>
      
    </span>
    <span class="item__date">
      <i class="fas fa-calendar-alt"></i> Oct 31, 2024
    </span>
    
    <span>
      
      
      
      
      
      
      <a class="badge badge-category" href="/category/iot">IOT</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/raspberry-pi">RASPBERRY PI</a>
      
      
      
      
    </span>
    

<p><img src="/images/mouse-jiggler.jpg#center" alt="A mouse jiggler" /></p>

<p>Today, my Amazon feed was flooded with mouse jiggler suggestions in various shapes, sizes, and features. A few days ago, during a chat with a friend, he mentioned wanting a device to keep his status active on Microsoft Teams while doing household chores. It was my first time hearing about such a gadget, and I found it fascinating to explore what it can do.</p>

<h3 id="what-is-a-mouse-jiggler"><strong>What is a Mouse Jiggler?</strong></h3>

<p>In a nutshell, mouse jiggler is a device which moves your mouse or simulate its movement to keep your computer active.</p>

<p>The cheapest mouse jiggler I can found on Amazon was around Rs. 880 or $11 (approx.). Now mouse and keyboard are Human Interface Device (HID) and this can be easily mimic with something like a cheap Raspberry PI Pico and the total cost of this will be around Rs. 330 or $4.00.</p>

<h3 id="how-to-build"><strong>How to build?</strong></h3>

<p>Grab a Raspberry PI Pico from <a href="https://robu.in">Robu.in</a> or <a href="https://thingbits.in">ThingBits.in</a> as these are the official reseller of Raspberry PIs in India.</p>

<h3 id="download-and-install-thonny"><strong>Download and Install Thonny</strong></h3>

<p><a href="https://thonny.org/">Thonny</a> is a Python IDE which has excellent support for Raspberry PI. I will be using this IDE so the steps are more clear to anyone who is working with a RPI for the first time.</p>

<h3 id="configuring-the-ide"><strong>Configuring the IDE</strong></h3>

<p>After the installation is complete, plug the Pico to your computer while holding the BOOTSEL button on the PICO. This will put the PICO in the <code>bootloader</code> mode.</p>

<p>Click the bottom right corner of the main window, and select <code>Configure interpreter</code>.</p>

<p><img src="/images/thonny-change-interpreter.png" alt="Change Interpreter" /></p>

<p>Thonny options window will pop up where you will now click <code>Install or update CircuitPython(UF2)</code>.</p>

<p><img src="/images/thonny-options.png" alt="Thonny Options" /></p>

<p><img src="/images/thonny-install-ciruitpython.png" alt="Thonny installing CircuitPython" /></p>

<p>Click <code>Install</code> to start the installation and wait for it to finish. The device will restart after the installation is completed.</p>

<h3 id="install-dependencies"><strong>Install dependencies</strong></h3>

<p>We need Adafruit&rsquo;s HID library which you can download from <a href="https://circuitpython.org/libraries">here</a>. Extract the contents of the zip file and copy <code>adafruit_hid</code> folder to the <code>lib</code> folder which is at the root of the Pico.</p>

<h3 id="code-code-code"><strong>Code Code Code</strong></h3>

<p>If you are using Thonny then open <code>code.py</code> file by pressing <code>CTRL + O</code> and paste in the following code.</p>

<p><img src="/images/thonny-file-open.png" alt="Thonny file open" /></p>

<blockquote>
<p>NOTE: You will not see this dialog box if you have a wrong backend or no backend selected. You can change or select the right backend from the bottom right corner of of the Thonny IDE.</p>
</blockquote>

<pre class="brush:python">
import usb_hid
from adafruit_hid.mouse import Mouse
from time import sleep

m = Mouse(usb_hid.devices)

while True:
       m.move(-5, 0, 0)
       sleep(0.5)
       m.move(5, 0, 0)
       sleep(0.5)
</pre>

<p>The line from <code>adafruit_hid.mouse import Mouse</code> imports the Mouse dependency, allowing us to control the mouse programmatically. The code is straightforward and can be tailored to your specific needs. In my case, I want to move the mouse slightly to keep my status active while I&rsquo;m away. You can increase the time interval beyond <code>0.5</code> seconds, as both Teams and Slack take a while to detect inactivity before marking your status as inactive.</p>

<p>Currently, this Raspberry Pi Pico-based Mouse Jiggler is a fixture on my other always-on machine, saving me from having to re-login whenever I forget to move the mouse while deep in work.</p>

  </div>
  
  <div class="post-list__item">
    <span class="item__title--big">
      <a href="/post/setting-up-virtuanes-emulator-for-retro-gaming-on-windows/">Setting Up VirtuaNES Emulator For Retro Gaming On Windows</a>
      
    </span>
    <span class="item__date">
      <i class="fas fa-calendar-alt"></i> Jun 19, 2023
    </span>
    
    <span>
      
      
      
      
      
      
      <a class="badge badge-category" href="/category/emulator">EMULATOR</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/gaming">GAMING</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/windows">WINDOWS</a>
      
      
      
      
    </span>
    

<p>I grew up playing all the 90s games and I still love them. For quite a sometime I am now using VirtuaNES emulator to do retro gaming on my Windows machine. There are other NES emulators out there but this is the one I have been using now for a while and it has been good so far.</p>

<p>To setup VirtuaNES emulator on Windows, download it from <a href="https://www.emulatorgames.net/emulators/nintendo/virtualnes-0-9-7/">here</a> and <a href="https://www.emulator-zone.com/doc.php/nes/virtuanes.html">here</a>. Once you download the zip file, extract the content to any folder and double click the <code>VirtuaNES.exe</code> to run the emulator.</p>

<p><img src="/images/virtuanes-extract-folder.png" alt="VirtuaNES files after extraction" /></p>

<p>After the emulator is launched, we can start configuring the sound and controller. If you are a keyboard person, then no configuration is needed, you can instantly load a ROM and start playing the game. The default keys are as follows (yours might look a little different):</p>

<p>Go to <strong>Options -&gt; Controller</strong> to change the keyboard bindings or your controller bindings.</p>

<p><img src="/images/virtuanes-keyboard-maps.png" alt="VirtuaNES keyboard settings" /></p>

<blockquote>
<p>XBOX One controller is also compatible and you can configure it easily. Make sure to turn on or plug in the controller before you start the emulator.</p>
</blockquote>

<p>Here is the screenshot of the bindings of my XBox One controller.</p>

<p><img src="/images/virtuanes-xbox-bindings.png" alt="VirtuaNES xbox controller bindings" /></p>

<p>For configuring the sound settings, go to <strong>Options -&gt; Sound</strong></p>

<p><img src="/images/virtuanes-sound-settings.png" alt="VirtuaNES sound settings" /></p>

<p>Even after setting up the sound, there is a chance that you can&rsquo;t hear it when you play the game. That is due to a setting in the audio settings section in Windows. Refer the below screenshot and check whether the <code>Mono audio</code> is <code>off</code> or <code>on</code>. If it is <code>off</code>, then you have to turn it <code>on</code> and that will solve the sound problem in the emulator.</p>

<p><img src="/images/virtuanes-system-sound-settings.png" alt="VirtuaNES system sound settings" /></p>

<p>All set now!! Let&rsquo;s get some games or ROMs as we call it and load it in the emulator. I downloaded few ROMs from <a href="https://www.emulatorgames.net/roms/nintendo/">Emulatorgames.net</a>. Extract the zip file and load the ROM in the emulator by going to <strong>File -&gt; Open</strong>. You should now see your childhood retro gaming console in front of you.</p>

<p><img src="/images/virtuanes-emulator-running.png" alt="VirtuaNES emulator running" /></p>

<h3 id="links">Links</h3>

<ul>
<li><a href="https://www.emulatorgames.net/">Emulator Games</a></li>
<li><a href="https://www.emulatorgames.net/roms/">ROMs for all platform emulators</a></li>
<li><a href="https://www.emulatorgames.net/emulators/">Other emulators</a></li>
</ul>

  </div>
  
  <div class="post-list__item">
    <span class="item__title--big">
      <a href="/post/geo-distributed-load-testing-via-k6-and-azure-container-instance/">Geo-Distributed Load Testing via K6 and Azure Container Instances</a>
      
    </span>
    <span class="item__date">
      <i class="fas fa-calendar-alt"></i> Jun 2, 2023
    </span>
    
    <span>
      
      
      
      
      
      
      <a class="badge badge-category" href="/category/azure">AZURE</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/containers">CONTAINERS</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/k6">K6</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/testing">TESTING</a>
      
      
      
      
    </span>
    

<p>My team at Microsoft is responsible for building tools that enhance customer experience when you contact Microsoft support. Although our tools are never used by customers directly but they play an essential role in improving the experience and overall cost reductions. This means that our work is critical for the overall success and it should perform under variance of load, especially on holidays.</p>

<h3 id="problem-statement"><strong>Problem Statement</strong></h3>

<p>Team wants to test their application from different geographies and mark the metrics used.</p>

<p>I am not the primary team member leading the load testing project but it interests me a lot on how the other team is going to achieve this. Although they have a different plan to get this done, I came up with my own simple but useful way of getting these tests done via Azure Container Instances.</p>

<p>To accomplish this, I plan to use <a href="https://k6.io/">K6</a> load testing tool which is built specifically for engineering teams and by well-known <a href="https://grafana.com/">Grafana Labs.</a> I need to setup Azure Container Instances with K6 image and configure it with Azure File Share which acts as a volume mount.</p>

<h3 id="setting-up-resources-in-azure"><strong>Setting up resources in Azure</strong></h3>

<p>I will start up by setting a <code>Resource Group</code> in Azure and I will name it <code>cannon</code>. You can name it anything you want.</p>

<blockquote>
<p>I am using Azure CLI aka AZ CLI. If you have not setup AZ CLI for Azure, then I strongly suggest you do so. If you still choose not to use this, then you can still use Azure Portal, Terraform etc. to create these resources.</p>
</blockquote>

<h3 id="create-a-new-resource-group"><strong>Create a new Resource Group</strong></h3>

<pre class="brush:bash">
$ az group ceate --name cannon --location eastus
</pre>

<h3 id="create-a-new-azure-storage-account"><strong>Create a new Azure Storage Account</strong></h3>

<p>I need an Azure Storage account because File Share service is a part of Azure Storage.</p>

<p>The below command will create a new Azure Storage account inside the resource group cannon with <code>Performance</code> tier as <code>Standard</code> and <code>Redundancy</code> as <code>Locally-redundant storage</code>. You can change these values as per your need.</p>

<pre class="brush:bash">
$ az storage account create --name geoloadteststore \
 --resource-group cannon \
 --location eastus \
 --sku Standard_LRS
 </pre>

<h3 id="create-a-new-file-share"><strong>Create a new File Share</strong></h3>

<p>The below command will create a new file share which I will use as a volume mount for my Azure Container Instance.</p>

<pre class="brush:bash">
az storage share create \
--account-name geoloadteststore \
--name loadtestresults \
--quota 1
</pre>

<p>In the above command, <code>account-name</code> and <code>name</code> are mandatory, <code>quota</code> is a non-mandatory parameter, but I have used it to ensure that the share size is not set to default which is <strong>5TB</strong>. Setting <code>quota</code> as 1 will set the size of my share to be <strong>1GB</strong>.</p>

<h3 id="create-and-run-azure-container-instance"><strong>Create and run Azure Container Instance</strong></h3>

<p>When I create a new Azure Container Instance, it will use an image to create a container and run it. This means that I don’t have to run the container explicitly unless there is an error.</p>

<p>Here is an AZ command that will create a new Azure Container Instance and execute the load test using K6.</p>

<pre class="brush:bash">
az container create -n k6demo \
--resource-group cannon \
--location eastus
--image grafana/k6:latest \
--azure-file-volume-account-name geoloadteststore \
--azure-file-volume-account-key RhGutivQKlz5llXx9gPxM/CP/dlXWLw5x6/SHyCl+GtLZeRp9cAYEByYTo3vL2EFAy0Nz0H+n1CV+AStTNGEmA== \
--azure-file-volume-share-name loadtestresults \
--azure-file-volume-mount-path /results \
--command-line "k6 run --duration 10s --vus 5 /results/tests/script_eastus.js --out json=/results/logs/test_results_eastus.json" \
--restart-policy Never
</pre>

<p>The above command has lots of details and few parts of it require some good attention. For most of the part, things are simple to understand. The <a href="https://hub.docker.com/r/grafana/k6">image</a> that I am using is provided to us by Grafana from their verified Docker Hub account. I then use the Azure File share information to setup the volume mount.</p>

<p>The important part here is the way the volume mount is used. The <code>--azure-file-volume-mount-path</code> has the value <code>/results</code> which will be a mount path in the container. This means that you <strong>don&rsquo;t have to create a folder</strong> named <strong>results</strong> in the file share. If you take your attention to the next parameter <code>--command-line</code>, you can see that the K6 test script is being read from <code>/result/tests</code> folder and output of the command is stored in <code>/results/logs</code>. If you wish, you can also use a full path of a blob storage or even an S3 bucket to read your script file.</p>

<p>Navigate to the file share in Azure Portal and create 2 folders named <code>logs</code> and <code>tests</code>.</p>

<p><img src="/images/logsntestfolders.png" alt="logs and test folder" /></p>

<p>Inside the tests folder, add a K6 script file you have created. I have created multiple script files for different locations.</p>

<p><img src="/images/test-folder-content.png" alt="Contents of the tests folder" /></p>

<p>For this example, I am using a demo script with some changes to it. Note the change in the name of the summary file. It contains the location name for easy identification of logs.</p>

<pre class="brush:js">
import http from "k6/http";
import { sleep } from "k6";

export default function () {
  http.get("https://test.k6.io");
  sleep(1);
}

export function handleSummary(data) {
  return {
    "/results/logs/summary_eastus.json": JSON.stringify(data), //the default data object
  };
}
</pre>

<p>As per K6 documentation, I have added an additional function named <code>handleSummary</code>. This function will generate the summary for the entire test and save it in the JSON format which later I can use for visualization. This is the same output you will see when you run the K6 on your console. The other file which is referenced in the command above called <code>test_results_eastus.json</code> will have details about every test run.</p>

<p>I execute the <code>az container create</code> command three times for 3 different regions.</p>

<p><img src="/images/container-instances-for-testing.png" alt="Container instances for testing" /></p>

<p>I have 3 Azure Container Instances which ran by K6 load test for 3 different locations. You can also see the location for each Azure Container Instance in the above screenshot. After the load test is finished, I can now view my JSON logs in the file share.</p>

<p><img src="/images/load-testing-results.png" alt="Load testing results" /></p>

<p>This way I can run the load test on my web apps or services hosted from anywhere or at least from all the Azure regions.</p>

<h3 id="improvement-areas"><strong>Improvement Areas</strong></h3>

<p>With the above working as expected, I think there are few things that I can really improve on.</p>

<h4 id="automation"><strong>Automation</strong></h4>

<p>The entire work is manual and is error prone. It will be good to automate this entire process with less user intervention when it comes to execution. Writing load tests would be user responsibility though. Going forward, I would like to automate the creation of all these resources using Terraform and then execute the TF scripts automatically. If you want to do this for any of your Terraforms projects, refer my article on <strong><a href="https://medium.com/@prashantkhandelwal/create-azure-resources-programmatically-by-executing-terraform-commands-in-go-ff2182513ee2">medium</a></strong>.</p>

<h4 id="visualization"><strong>Visualization</strong></h4>

<p>After getting the test logs from the File Share, I also want to see what the load test results look like. As of now there is no tool I have to do so. But there are few I found on the GitHub that allow me to visualize the output of K6 load tests. Maybe I would write one or use an open-source, I am not sure about that at the moment.</p>

<p>I hope you enjoyed this article and learn one or more things related to Azure and K6. Here are few more resources that will be helpful.</p>

<ul>
<li><a href="https://learn.microsoft.com/en-us/cli/azure/container?view=azure-cli-latest">az contianer cli - documentation</a></li>
<li><a href="https://k6.io/docs/">K6 - Official documentation</a></li>
<li><a href="https://k6.io/docs/results-output/end-of-test/custom-summary/">handleSummary or Custom Summary with K6</a></li>
</ul>

  </div>
  
  <div class="post-list__item">
    <span class="item__title--big">
      <a href="/post/create-azure-resources-programmatically-by-executing-terraform-commands-in-go/">Create Azure Resources Programmatically By Executing Terraform Commands in Go</a>
      
    </span>
    <span class="item__date">
      <i class="fas fa-calendar-alt"></i> May 4, 2023
    </span>
    
    <span>
      
      
      
      
      
      
      <a class="badge badge-category" href="/category/automation">AUTOMATION</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/azure">AZURE</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/devops">DEVOPS</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/go">GO</a>
      &nbsp;
      
      <a class="badge badge-category" href="/category/terraform">TERRAFORM</a>
      
      
      
      
    </span>
    

<p><a href="https://www.terraform.io/">Terraform</a> is my go-to IAC tool for building my infrastructure in Azure. I usually use Azure DevOps pipeline to execute my terraform plan, but it would be nice to know if I can execute it programmatically or on request basis. Even on request basis you can trigger a CI/CD pipeline to provision the infrastructure but maybe it is too much for a simple project to have.</p>

<p>One of the biggest pain points has been the authentication in command line tooling. I can execute my terraform plan if I have <code>az cli login</code> done on the shell/terminal I am using. I can also perform the same operation programmatically, but it will still open up a web browser and ask me for authentication. I don’t want user intervention when performing this operation. So, the way I can achieve this is by using <code>Service Principal</code>.</p>

<blockquote>
<p>You can also make use of Managed Service Identity or MSI but not all Azure resources support this. You can check the list of the resources <a href="https://learn.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/managed-identities-status">here</a>.</p>
</blockquote>

<p>The service principal I am planning to use will let me create any Azure resource. This is equivalent to <code>az login cli</code> command.</p>

<h3 id="setting-up-azure"><strong>Setting up Azure</strong></h3>

<p>Add a new <code>App registration</code> in Azure Active Directory. Give a name to your application and then select <code>Redirect URI</code> to be web and <code>URL</code> can be left blank. Click <code>Register</code> to create an application.</p>

<p><img src="/images/az-ad-appreg.png" alt="Azure AD app registration" /></p>

<p>In the Overview section, copy the <code>client id</code> and <code>tenant id</code>. You also need to have a <code>subscription id</code> which you can find in your Active Directory or in your subscription resource in the portal.</p>

<p><img src="/images/az-ad-appoverview.png" alt="Azure AD app overview" /></p>

<p>Click on <code>Certificates &amp; secrets</code>, and then click <code>+ New client secret</code>. Follow the instructions to create a new secret and once done, you should be presented with a secret which you should copy and save somewhere safe (preferably in Azure KeyVault) as this is the only time it will be visible to you.</p>

<p><img src="/images/az-ad-appids.png" alt="Azure app client secret" /></p>

<p>In the end you should have these values with you:</p>

<ul>
<li>Client Id</li>
<li>Client Secret</li>
<li>Subscription Id</li>
<li>Tenant Id</li>
</ul>

<p>Now if you try creating a new resource using Terraform, it will fail as the service principal does not have permissions to manage resources in your subscription. To grant permissions, go to <code>Subscriptions</code> in Azure portal and click <code>Access control (IAM)</code>.</p>

<p><img src="/images/az-subscription-iam.png" alt="Azure subscription IAM" /></p>

<p>Click on <code>Add role assignment</code> and then click <code>Privileged administrator roles</code>.</p>

<p><img src="/images/az-sub-iam-role.png" alt="Azure subscription IAM role" /></p>

<p>You can ignore the warning shown at the bottom, we need this option for adding <code>contributor</code> access to the subscription we want to manage.</p>

<p><img src="/images/az-sub-iam-role-assign.png" alt="Azure subscription IAM role assignment" /></p>

<p>Select <code>Contributor</code> from the list and click <code>Next</code>.</p>

<p><img src="/images/az-sub-iam-members.png" alt="Azure subscription IAM members" /></p>

<p>Select <code>User, group or service principal</code> and click <code>+ Select members</code>.</p>

<p><img src="/images/az-sub-iam-selectmem.png" alt="Azure subscription IAM select members" /></p>

<p>Search your application by name, select it and then click <code>Select</code>. Verify the details in the last step and click <code>Review + assign</code>.</p>

<p><img src="/images/az-sub-iam-review.png" alt="Azure subscription IAM review" /></p>

<p>Back to the <code>Access controls (IAM)</code> blade, you can see the role assignment to the subscription.</p>

<p><img src="/images/az-sub-iam-roles.png" alt="Azure subscription review roles" /></p>

<h3 id="setting-up-go-project"><strong>Setting up Go project</strong></h3>

<p>Let&rsquo;s see with a very basic example of getting this done programmatically. Setup a new go project and import these packages.</p>

<pre class="brush:ruby">
import (
    "fmt"
    "log"
    "os"

    "github.com/hashicorp/go-version"
    "github.com/hashicorp/hc-install/product"
    "github.com/hashicorp/hc-install/releases"
)
</pre>

<p>In the <code>main</code> function, add the below code:</p>

<pre class="brush:ruby">
os.Setenv("ARM_CLIENT_ID", "")
os.Setenv("ARM_CLIENT_SECRET", "")
os.Setenv("ARM_TENANT_ID", "")
os.Setenv("ARM_SUBSCRIPTION_ID", "")

//az login --service-principal -u CLIENT_ID -p CLIENT_SECRET --tenant TENANT_ID
cmd := exec.Command("az", "login", "--service-principal", "-u", os.Getenv("ARM_CLIENT_ID"), "-p", os.Getenv("ARM_CLIENT_SECRET"), "--tenant", os.Getenv("ARM_TENANT_ID"))
var stdoutBuf, stderrBuf bytes.Buffer
cmd.Stdout = io.MultiWriter(os.Stdout, &stdoutBuf)
cmd.Stderr = io.MultiWriter(os.Stderr, &stderrBuf)
err := cmd.Run()
if err != nil {
    log.Fatalf("cmd.Run() failed with %s\n", err)
}

outStr := string(stdoutBuf.Bytes())
fmt.Println(outStr)
</pre>

<p>The first thing we did was to set environment variables.</p>

<blockquote>
<p>Name the environment variables as shown in the above example. These are the same names which are internally used by Terraform.</p>
</blockquote>

<p>Normally I would use a service principal like this:</p>

<pre class="brush:bash">
$ az login --service-principal -u CLIENT_ID -p CLIENT_SECRET --tenant TENANT_ID 
</pre>

<p>As we are automating this process, we can use the exec.Command to execute this command with parameters like this:</p>

<pre class="brush:ruby">
cmd := exec.Command("az", "login", "--service-principal", "-u", os.Getenv("ARM_CLIENT_ID"), "-p", os.Getenv("ARM_CLIENT_SECRET"), "--tenant", os.Getenv("ARM_TENANT_ID")) 
</pre>

<p>This will get the service principal and assign it to the terminal where this application will be running.</p>

<p><img src="/images/tf-command-test.png" alt="az cli output" /></p>

<p>Moving ahead you can remove or comment out the above code and leave the environment variables as is in the code file.</p>

<p>As a next step you can also take the terraform binary from the environment variable and automate the execution just like above. But there is an efficient way of doing this and for that we must make slight changes to our code.</p>

<p>First, we need to check if terraform is installed on the machine or not. On my machine I have Terraform installed and added to the environment with the name <code>terraform</code>. In Go, I can get this path with the help of <code>os.Getenv</code> and pass in the name of the environment variable <code>terraform</code>.</p>

<p>If the path exists, then I will use that path and if not then I can install a specific version of Terraform. Here is the is the complete code for the above explanation:</p>

<pre class="brush:ruby">
package main

import (
    "context"
    "log"
    "os"

    "github.com/hashicorp/go-version"
    "github.com/hashicorp/hc-install/product"
    "github.com/hashicorp/hc-install/releases"
)

func main() {

    var execPath string
    var tfInstallDir string
    var err error
    tfBin := os.Getenv("terraform")

    if len(tfBin) > 0 {
        log.Printf("Found Terraform: %s", tfBin)
        execPath = filepath.Join(tfBin, "terraform.exe")
    } else {
        log.Print("Terraform not found....installing")
        installer := &releases.ExactVersion{
            Product: product.Terraform,
            Version: version.Must(version.NewVersion("1.4.6")),
        }

        wd, _ := os.Getwd()
        tfInstallDir = filepath.Join(wd, "tf")
        if _, err := os.Stat(tfInstallDir); err != nil {
            log.Printf("Installation directory not found...creating")
            if err = os.MkdirAll(tfInstallDir, os.ModePerm); err != nil {
                log.Fatalf("ERROR: Cannot create \"%s\" directory - %v", tfInstallDir, err.Error())
                panic(err)
            }

            installer.InstallDir = tfInstallDir

            log.Printf("Installing version: %s", installer.Version.String())

            execPath, err = installer.Install(context.Background())
            if err != nil {
                log.Fatalf("Error installing Terraform: %s", err)
            }

            execPath = filepath.Join(installer.InstallDir, "terraform.exe")
            log.Printf("Installed Terraform %s at %s", installer.Version.String(), execPath)
        } else {
            execPath = filepath.Join(tfInstallDir, "terraform.exe")
            log.Printf("Terraform %s found at %s", installer.Version.String(), execPath)
        }
    }
}
</pre>

<p>The above program first looks for the <code>terraform</code> environment variable and tries to get the value for it. If the value exists, <code>execPath</code> variable will hold its value. If not meaning that Terraform is not installed on this machine and requires installation. The two packages that will help us installing the right version of Terraform are:</p>

<ul>
<li>github.com/hashicorp/hc-install/product</li>
<li>github.com/hashicorp/hc-install/releases</li>
</ul>

<p>We first prepare the <code>installer</code> by providing the details of the product we want to install, in our case, it is <code>Terraform</code>. You can provide a specific version based on your requirements. If you want to install any specific version like <code>1.0.6</code> etc. You can provide the version number and it will be installed.</p>

<p>The <code>installer.Install</code> function will take in the <code>context</code> which will run in the <code>background</code> and perform the installation for us. Once the installation is completed, you can see the path of the Terraform binary.</p>

<p>Note that if I have not provided an installation path or a directory, the installation will be done in a temp location of your machine. If you don’t want the installation to be done in a temporary location and also want to speed up the execution, then set the <code>InstallDir</code> property to set the path for installation.</p>

<blockquote>
<p>Check the below code for <code>InstallDir</code> implementation.</p>
</blockquote>

<p>Next, we set up the working directory where our Terraform code is. We need to import a new package called <code>tfexec</code>:</p>

<pre class="brush:bash">
"github.com/hashicorp/terraform-exec/tfexec"
</pre>

<p>and the code:</p>

<pre class="brush:ruby">
workingDir := "iac" 
tf, err := tfexec.NewTerraform(workingDir, execPath) 
if err != nil { 
  log.Fatalf("Error running NewTerraform: %s", err) 
} 
</pre>

<p>The <code>NewTerrafrom</code> function takes in two parameters. First is the <code>working directory</code> where you have kept your <code>.tf</code> files and the second one is the <code>execPath</code>, which is the executable path of the Terraform binary.</p>

<p>After this we can perform terraform <code>init</code> and <code>apply</code> like this:</p>

<pre class="brush:ruby">
log.Print("Start executing TF Init")
err = tf.Init(context.Background(), tfexec.Upgrade(true))
if err != nil {
    log.Fatalf("Error running Init: %s", err)
}

log.Print("Finished running TF Init")

log.Print("Start running TF Apply")
err = tf.Apply(context.Background())
if err != nil {
    log.Fatalf("Error running Apply: %s", err)
}

log.Print("Finished running TF Apply")
</pre>

<p>Both <code>init</code> and <code>apply</code> code are simple to understand. The last one is the <code>show</code> command. If you have worked with terraform cli, you also want to show the <code>output</code> after <code>terraform apply</code> has been successful. The <code>output</code> variables defined in your <code>.tf</code> files will return values like IP address of the virtual machine or the DNS name which you can save or use somewhere else.</p>

<p>These are the contents of my <code>output.tf</code> file:</p>

<pre class="brush:bash">
output "public_ip_address" {
  value = azurerm_linux_virtual_machine.popcorndbvm.public_ip_address
}

output "tls_private_key" {
  value     = tls_private_key.popcornssh.private_key_openssh
  sensitive = true
}
</pre>

<p>We can also check if the output is marked as <code>sensitive</code> or not. You can see here that I have marked <code>tls_private_key</code> as <code>sensitive</code>. When you traverse the output variables, you can check the <code>Sensitive</code> property and prevent the value to be displayed in your terminal. Below is the code that does the same thing:</p>

<pre class="brush:ruby">
state, err := tf.Show(context.Background())
if err != nil {
    log.Fatalf("Error running Show: %s", err)
}

for s, i := range state.Values.Outputs {
    val := i.Value
    if s == "tls_private_key" && i.Sensitive {
        data := val.(string)
        err := ioutil.WriteFile("propcornvm_key.key", []byte(data), 0)
        if err != nil {
            log.Fatalf("Cannot save private key to the local machine. - %s", err.Error())
        } else {
            fmt.Printf("Private Key saved: %s\n", "propcornvm_key.key")
        }
    } else {
        fmt.Printf("%s : %s", s, val)
        fmt.Println()
    }
}
</pre>

<p>The <code>state</code> variable is a pointer to <code>*tfjson.State</code> and once it runs successfully the output will be stored in a <code>map[string]*tfjson</code>.<code>StateOutput</code>, which we can iterate over to get the values of the <code>output</code> variables.</p>

<blockquote>
<p>NOTE: You can use my terraform files to create a web app, app service plan, Linux virtual machine etc. You can view these files <a href="https://github.com/prashantkhandelwal/Popcorn/tree/main/Deployment/Azure">here</a>.</p>
</blockquote>

<p>Here is the complete code. You need to update the environment variables and replace them with the variables you have obtained from Azure portal. Set <code>workingDir</code> variable with the name of the path where your <code>tf</code> files are.</p>

<pre class="brush:ruby">
package main

import (
    "context"
    "fmt"
    "io/ioutil"
    "log"
    "os"
    "path/filepath"

    "github.com/hashicorp/go-version"
    "github.com/hashicorp/hc-install/product"
    "github.com/hashicorp/hc-install/releases"
    "github.com/hashicorp/terraform-exec/tfexec"
)

func main() {

    // Update these environment variables with yours.
    os.Setenv("ARM_CLIENT_ID", "")
    os.Setenv("ARM_CLIENT_SECRET", "")
    os.Setenv("ARM_TENANT_ID", "")
    os.Setenv("ARM_SUBSCRIPTION_ID", "")

    //az login --service-principal -u CLIENT_ID -p CLIENT_SECRET --tenant TENANT_ID
    // cmd := exec.Command("az", "login", "--service-principal", "-u", os.Getenv("ARM_CLIENT_ID"), "-p", os.Getenv("ARM_CLIENT_SECRET"), "--tenant", os.Getenv("ARM_TENANT_ID"))
    // var stdoutBuf, stderrBuf bytes.Buffer
    // cmd.Stdout = io.MultiWriter(os.Stdout, &stdoutBuf)
    // cmd.Stderr = io.MultiWriter(os.Stderr, &stderrBuf)
    // err := cmd.Run()
    // if err != nil {
    //  log.Fatalf("cmd.Run() failed with %s\n", err)
    // }

    // outStr := string(stdoutBuf.Bytes())
    // fmt.Println(outStr)

    var execPath string
    var tfInstallDir string
    var err error
    tfBin := os.Getenv("terraform1")

    if len(tfBin) > 0 {
        log.Printf("Found Terraform: %s", tfBin)
        execPath = filepath.Join(tfBin, "terraform.exe")
    } else {
        log.Print("Terraform not found....installing")
        installer := &releases.ExactVersion{
            Product: product.Terraform,
            Version: version.Must(version.NewVersion("1.4.6")),
        }

        wd, _ := os.Getwd()
        tfInstallDir = filepath.Join(wd, "tf")
        if _, err := os.Stat(tfInstallDir); err != nil {
            log.Printf("Installation directory not found...creating")
            if err = os.MkdirAll(tfInstallDir, os.ModePerm); err != nil {
                log.Fatalf("ERROR: Cannot create \"%s\" directory - %v", tfInstallDir, err.Error())
                panic(err)
            }

            installer.InstallDir = tfInstallDir

            log.Printf("Installing version: %s", installer.Version.String())

            execPath, err = installer.Install(context.Background())
            if err != nil {
                log.Fatalf("Error installing Terraform: %s", err)
            }

            execPath = filepath.Join(installer.InstallDir, "terraform.exe")
            log.Printf("Installed Terraform %s at %s", installer.Version.String(), execPath)
        } else {
            execPath = filepath.Join(tfInstallDir, "terraform.exe")
            log.Printf("Terraform %s found at %s", installer.Version.String(), execPath)
        }
    }

    workingDir := "iac"
    tf, err := tfexec.NewTerraform(workingDir, execPath)
    if err != nil {
        log.Fatalf("Error running NewTerraform: %s", err)
    }

    log.Print("Start executing TF Init")
    err = tf.Init(context.Background(), tfexec.Upgrade(true))
    if err != nil {
        log.Fatalf("Error running Init: %s", err)
    }

    log.Print("Finished running TF Init")

    log.Print("Start running TF Apply")
    err = tf.Apply(context.Background())
    if err != nil {
        log.Fatalf("Error running Apply: %s", err)
    }

    log.Print("Finished running TF Apply")

    state, err := tf.Show(context.Background())
    if err != nil {
        log.Fatalf("Error running Show: %s", err)
    }

    for s, i := range state.Values.Outputs {
        val := i.Value
        if s == "tls_private_key" && i.Sensitive {
            data := val.(string)
            err := ioutil.WriteFile("propcornvm_key.key", []byte(data), 0)
            if err != nil {
                log.Fatalf("Cannot save private key to the local machine. - %s", err.Error())
            } else {
                fmt.Printf("Private Key saved: %s\n", "propcornvm_key.key")
            }
        } else {
            fmt.Printf("%s : %s", s, val)
            fmt.Println()
        }
    }
}
</pre>

<p><code>terraform-exec</code> module is used to construct the terraform commands. <a href="https://github.com/hashicorp/terraform-exec/">Take a look at its repository</a>.</p>

<p>Before you plan to use this module in your production environment, consider the below excerpt from the repository readme file:</p>

<blockquote>
<p>While terraform-exec is already widely used, please note that this module is not yet at v1.0.0, and that therefore breaking changes may occur in minor releases.</p>
</blockquote>

<p>Here is the output of the above example, when I run it with my Azure service principal.</p>

<p><img src="/images/az-tf-go-output.png" alt="Terraform automation output" /></p>

<p>You can see 1 output variable <code>public_ip_address</code> and because we have marked the other output variable as sensitive, it is not shown here in the terminal, instead its output is stored in a file named <code>popcornvm_key.key</code>.</p>

<p>We see all our resources are successfully created in Azure portal.</p>

<p><img src="/images/az-tf-result.png" alt="Azure resources created via automation" /></p>

  </div>
  
</div>


<ul class="pagination">
    
    <li class="page-item">
        <a href="/" class="page-link" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li class="page-item disabled">
    <a href="" class="page-link" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item active"><a class="page-link" href="/">1</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/page/2/">2</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/page/3/">3</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item disabled"><span aria-hidden="true">&nbsp;&hellip;&nbsp;</span></li>
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/page/34/">34</a></li>
    
    
    <li class="page-item">
    <a href="/page/2/" class="page-link" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li class="page-item">
        <a href="/page/34/" class="page-link" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>


        </div>
        



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-QYXJT2TJCG', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script defer src="https://use.fontawesome.com/releases/v5.2.0/js/all.js"
  integrity="sha384-4oV5EgaV02iISL2ban6c/RmotsABqE4yZxZLcYMAdG7FAPsyHYAPpywE9PJo+Khy"
  crossorigin="anonymous">
</script>

<link
  href="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/styles/shCore.min.css"
  rel="stylesheet"
/>
<link
  href="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/styles/shThemeDefault.min.css"
  rel="stylesheet"
/>

<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shCore.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shBrushCSharp.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shBrushCss.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shBrushJScript.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shBrushPlain.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shBrushSql.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shBrushXml.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shBrushPowerShell.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shBrushPython.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shBrushBash.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shBrushCpp.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/SyntaxHighlighter/3.0.83/scripts/shBrushRuby.min.js"
></script>

<script>
  SyntaxHighlighter.defaults["gutter"] = true;
  SyntaxHighlighter.defaults["smart-tabs"] = true;
  SyntaxHighlighter.defaults["auto-links"] = true;
  SyntaxHighlighter.defaults["collapse"] = false;
  SyntaxHighlighter.defaults["light"] = false;
  SyntaxHighlighter.defaults["tab-size"] = 4;
  SyntaxHighlighter.defaults["toolbar"] = false;
  SyntaxHighlighter.defaults["wrap-lines"] = true;
  SyntaxHighlighter.all();
</script>


    </body>
</html>
